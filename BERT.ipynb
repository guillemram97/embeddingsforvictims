{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "#from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa \n",
    "from keras import metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 176ms/step - loss: 1.0937 - accuracy: 0.3361 - f1_score: 0.2920 - val_loss: 0.9537 - val_accuracy: 0.5110 - val_f1_score: 0.2917\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9592 - accuracy: 0.4961 - f1_score: 0.2916 - val_loss: 0.9413 - val_accuracy: 0.5110 - val_f1_score: 0.2914\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9484 - accuracy: 0.4992 - f1_score: 0.2913 - val_loss: 0.9352 - val_accuracy: 0.5110 - val_f1_score: 0.2911\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9442 - accuracy: 0.4963 - f1_score: 0.2910 - val_loss: 0.9293 - val_accuracy: 0.5110 - val_f1_score: 0.2907\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9366 - accuracy: 0.4982 - f1_score: 0.2906 - val_loss: 0.9235 - val_accuracy: 0.5110 - val_f1_score: 0.2904\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.9331 - accuracy: 0.4944 - f1_score: 0.2903 - val_loss: 0.9179 - val_accuracy: 0.5110 - val_f1_score: 0.2901\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9284 - accuracy: 0.4924 - f1_score: 0.2900 - val_loss: 0.9125 - val_accuracy: 0.5110 - val_f1_score: 0.2898\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9214 - accuracy: 0.4944 - f1_score: 0.2897 - val_loss: 0.9074 - val_accuracy: 0.5110 - val_f1_score: 0.2894\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9137 - accuracy: 0.4980 - f1_score: 0.2893 - val_loss: 0.9024 - val_accuracy: 0.5110 - val_f1_score: 0.2891\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9120 - accuracy: 0.4918 - f1_score: 0.2890 - val_loss: 0.8976 - val_accuracy: 0.5110 - val_f1_score: 0.2888\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9069 - accuracy: 0.4918 - f1_score: 0.2887 - val_loss: 0.8930 - val_accuracy: 0.5110 - val_f1_score: 0.2885\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.9001 - accuracy: 0.4952 - f1_score: 0.2884 - val_loss: 0.8886 - val_accuracy: 0.5110 - val_f1_score: 0.2882\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8959 - accuracy: 0.4941 - f1_score: 0.2881 - val_loss: 0.8843 - val_accuracy: 0.5110 - val_f1_score: 0.2879\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8913 - accuracy: 0.4942 - f1_score: 0.2878 - val_loss: 0.8802 - val_accuracy: 0.5110 - val_f1_score: 0.2876\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8878 - accuracy: 0.4920 - f1_score: 0.2875 - val_loss: 0.8762 - val_accuracy: 0.5110 - val_f1_score: 0.2873\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8843 - accuracy: 0.4903 - f1_score: 0.2872 - val_loss: 0.8724 - val_accuracy: 0.5110 - val_f1_score: 0.2870\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8784 - accuracy: 0.4945 - f1_score: 0.2869 - val_loss: 0.8687 - val_accuracy: 0.5110 - val_f1_score: 0.2867\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8752 - accuracy: 0.4925 - f1_score: 0.2866 - val_loss: 0.8652 - val_accuracy: 0.5110 - val_f1_score: 0.2864\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8710 - accuracy: 0.4935 - f1_score: 0.2863 - val_loss: 0.8617 - val_accuracy: 0.5110 - val_f1_score: 0.2861\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8671 - accuracy: 0.4941 - f1_score: 0.2860 - val_loss: 0.8584 - val_accuracy: 0.5110 - val_f1_score: 0.2858\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8638 - accuracy: 0.4933 - f1_score: 0.2857 - val_loss: 0.8551 - val_accuracy: 0.5110 - val_f1_score: 0.2856\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8604 - accuracy: 0.4932 - f1_score: 0.2855 - val_loss: 0.8520 - val_accuracy: 0.5110 - val_f1_score: 0.2853\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8565 - accuracy: 0.4948 - f1_score: 0.2852 - val_loss: 0.8489 - val_accuracy: 0.5110 - val_f1_score: 0.2850\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8522 - accuracy: 0.4981 - f1_score: 0.2849 - val_loss: 0.8460 - val_accuracy: 0.5110 - val_f1_score: 0.2847\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8501 - accuracy: 0.4947 - f1_score: 0.2846 - val_loss: 0.8431 - val_accuracy: 0.5110 - val_f1_score: 0.2844\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8461 - accuracy: 0.4980 - f1_score: 0.2843 - val_loss: 0.8403 - val_accuracy: 0.5110 - val_f1_score: 0.2842\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8432 - accuracy: 0.4982 - f1_score: 0.2841 - val_loss: 0.8375 - val_accuracy: 0.5110 - val_f1_score: 0.2839\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8419 - accuracy: 0.4925 - f1_score: 0.2838 - val_loss: 0.8349 - val_accuracy: 0.5110 - val_f1_score: 0.2836\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8385 - accuracy: 0.4946 - f1_score: 0.2835 - val_loss: 0.8323 - val_accuracy: 0.5110 - val_f1_score: 0.2834\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8336 - accuracy: 0.5034 - f1_score: 0.2833 - val_loss: 0.8298 - val_accuracy: 0.5110 - val_f1_score: 0.2831\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8326 - accuracy: 0.4968 - f1_score: 0.2830 - val_loss: 0.8273 - val_accuracy: 0.5110 - val_f1_score: 0.2828\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8293 - accuracy: 0.5000 - f1_score: 0.2828 - val_loss: 0.8249 - val_accuracy: 0.5110 - val_f1_score: 0.2826\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.8258 - accuracy: 0.5045 - f1_score: 0.2825 - val_loss: 0.8226 - val_accuracy: 0.5110 - val_f1_score: 0.2823\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8246 - accuracy: 0.4990 - f1_score: 0.2822 - val_loss: 0.8203 - val_accuracy: 0.5110 - val_f1_score: 0.2821\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8245 - accuracy: 0.4885 - f1_score: 0.2820 - val_loss: 0.8181 - val_accuracy: 0.5110 - val_f1_score: 0.2818\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8203 - accuracy: 0.4975 - f1_score: 0.2817 - val_loss: 0.8159 - val_accuracy: 0.5110 - val_f1_score: 0.2816\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8182 - accuracy: 0.4968 - f1_score: 0.2815 - val_loss: 0.8138 - val_accuracy: 0.5110 - val_f1_score: 0.2813\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.8157 - accuracy: 0.4982 - f1_score: 0.2812 - val_loss: 0.8117 - val_accuracy: 0.5110 - val_f1_score: 0.2811\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.8133 - accuracy: 0.4996 - f1_score: 0.2810 - val_loss: 0.8096 - val_accuracy: 0.5110 - val_f1_score: 0.2808\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8114 - accuracy: 0.4987 - f1_score: 0.2807 - val_loss: 0.8077 - val_accuracy: 0.5110 - val_f1_score: 0.2806\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8091 - accuracy: 0.5000 - f1_score: 0.2805 - val_loss: 0.8057 - val_accuracy: 0.5110 - val_f1_score: 0.2803\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8084 - accuracy: 0.4931 - f1_score: 0.2803 - val_loss: 0.8038 - val_accuracy: 0.5110 - val_f1_score: 0.2801\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8060 - accuracy: 0.4955 - f1_score: 0.2800 - val_loss: 0.8020 - val_accuracy: 0.5110 - val_f1_score: 0.2799\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8032 - accuracy: 0.5011 - f1_score: 0.2798 - val_loss: 0.8002 - val_accuracy: 0.5110 - val_f1_score: 0.2796\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8021 - accuracy: 0.4963 - f1_score: 0.2795 - val_loss: 0.7984 - val_accuracy: 0.5110 - val_f1_score: 0.2794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.8005 - accuracy: 0.4952 - f1_score: 0.2793 - val_loss: 0.7967 - val_accuracy: 0.5110 - val_f1_score: 0.2792\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7988 - accuracy: 0.4943 - f1_score: 0.2791 - val_loss: 0.7950 - val_accuracy: 0.5110 - val_f1_score: 0.2789\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7961 - accuracy: 0.5011 - f1_score: 0.2789 - val_loss: 0.7934 - val_accuracy: 0.5110 - val_f1_score: 0.2787\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7957 - accuracy: 0.4925 - f1_score: 0.2786 - val_loss: 0.7918 - val_accuracy: 0.5110 - val_f1_score: 0.2785\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7938 - accuracy: 0.4936 - f1_score: 0.2784 - val_loss: 0.7902 - val_accuracy: 0.5110 - val_f1_score: 0.2782\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7921 - accuracy: 0.4942 - f1_score: 0.2782 - val_loss: 0.7886 - val_accuracy: 0.5110 - val_f1_score: 0.2780\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7903 - accuracy: 0.4962 - f1_score: 0.2780 - val_loss: 0.7871 - val_accuracy: 0.5110 - val_f1_score: 0.2778\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7884 - accuracy: 0.4991 - f1_score: 0.2777 - val_loss: 0.7857 - val_accuracy: 0.5110 - val_f1_score: 0.2776\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7878 - accuracy: 0.4917 - f1_score: 0.2775 - val_loss: 0.7842 - val_accuracy: 0.5110 - val_f1_score: 0.2774\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7857 - accuracy: 0.4967 - f1_score: 0.2773 - val_loss: 0.7828 - val_accuracy: 0.5110 - val_f1_score: 0.2772\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7841 - accuracy: 0.4981 - f1_score: 0.2771 - val_loss: 0.7814 - val_accuracy: 0.5110 - val_f1_score: 0.2769\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7825 - accuracy: 0.4996 - f1_score: 0.2769 - val_loss: 0.7801 - val_accuracy: 0.5110 - val_f1_score: 0.2767\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7819 - accuracy: 0.4935 - f1_score: 0.2767 - val_loss: 0.7788 - val_accuracy: 0.5110 - val_f1_score: 0.2765\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7799 - accuracy: 0.4982 - f1_score: 0.2764 - val_loss: 0.7775 - val_accuracy: 0.5110 - val_f1_score: 0.2763\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7785 - accuracy: 0.4996 - f1_score: 0.2762 - val_loss: 0.7762 - val_accuracy: 0.5110 - val_f1_score: 0.2761\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7767 - accuracy: 0.5036 - f1_score: 0.2760 - val_loss: 0.7749 - val_accuracy: 0.5110 - val_f1_score: 0.2759\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7752 - accuracy: 0.5057 - f1_score: 0.2758 - val_loss: 0.7737 - val_accuracy: 0.5110 - val_f1_score: 0.2757\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7751 - accuracy: 0.4957 - f1_score: 0.2756 - val_loss: 0.7726 - val_accuracy: 0.5110 - val_f1_score: 0.2755\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7734 - accuracy: 0.5000 - f1_score: 0.2754 - val_loss: 0.7714 - val_accuracy: 0.5110 - val_f1_score: 0.2753\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7724 - accuracy: 0.4990 - f1_score: 0.2752 - val_loss: 0.7703 - val_accuracy: 0.5110 - val_f1_score: 0.2751\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7716 - accuracy: 0.4954 - f1_score: 0.2750 - val_loss: 0.7692 - val_accuracy: 0.5110 - val_f1_score: 0.2749\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7708 - accuracy: 0.4923 - f1_score: 0.2748 - val_loss: 0.7681 - val_accuracy: 0.5110 - val_f1_score: 0.2747\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7694 - accuracy: 0.4950 - f1_score: 0.2746 - val_loss: 0.7670 - val_accuracy: 0.5110 - val_f1_score: 0.2745\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7683 - accuracy: 0.4948 - f1_score: 0.2744 - val_loss: 0.7659 - val_accuracy: 0.5110 - val_f1_score: 0.2743\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7678 - accuracy: 0.4890 - f1_score: 0.2742 - val_loss: 0.7649 - val_accuracy: 0.5110 - val_f1_score: 0.2741\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7667 - accuracy: 0.4896 - f1_score: 0.2740 - val_loss: 0.7639 - val_accuracy: 0.5110 - val_f1_score: 0.2739\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7646 - accuracy: 0.5003 - f1_score: 0.2738 - val_loss: 0.7629 - val_accuracy: 0.5110 - val_f1_score: 0.2737\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7647 - accuracy: 0.4887 - f1_score: 0.2736 - val_loss: 0.7620 - val_accuracy: 0.5110 - val_f1_score: 0.2735\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7625 - accuracy: 0.5022 - f1_score: 0.2735 - val_loss: 0.7610 - val_accuracy: 0.5110 - val_f1_score: 0.2733\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7626 - accuracy: 0.4905 - f1_score: 0.2733 - val_loss: 0.7601 - val_accuracy: 0.5110 - val_f1_score: 0.2731\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7604 - accuracy: 0.5051 - f1_score: 0.2731 - val_loss: 0.7592 - val_accuracy: 0.5110 - val_f1_score: 0.2730\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7603 - accuracy: 0.4952 - f1_score: 0.2729 - val_loss: 0.7583 - val_accuracy: 0.5110 - val_f1_score: 0.2728\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7597 - accuracy: 0.4915 - f1_score: 0.2727 - val_loss: 0.7574 - val_accuracy: 0.5110 - val_f1_score: 0.2726\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7581 - accuracy: 0.5002 - f1_score: 0.2725 - val_loss: 0.7566 - val_accuracy: 0.5110 - val_f1_score: 0.2724\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7571 - accuracy: 0.5011 - f1_score: 0.2724 - val_loss: 0.7557 - val_accuracy: 0.5110 - val_f1_score: 0.2722\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7568 - accuracy: 0.4940 - f1_score: 0.2722 - val_loss: 0.7549 - val_accuracy: 0.5110 - val_f1_score: 0.2721\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7558 - accuracy: 0.4961 - f1_score: 0.2720 - val_loss: 0.7541 - val_accuracy: 0.5110 - val_f1_score: 0.2719\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7552 - accuracy: 0.4942 - f1_score: 0.2718 - val_loss: 0.7533 - val_accuracy: 0.5110 - val_f1_score: 0.2717\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.7539 - accuracy: 0.5006 - f1_score: 0.2716 - val_loss: 0.7525 - val_accuracy: 0.5110 - val_f1_score: 0.2715\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7536 - accuracy: 0.4930 - f1_score: 0.2715 - val_loss: 0.7518 - val_accuracy: 0.5110 - val_f1_score: 0.2714\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7525 - accuracy: 0.4974 - f1_score: 0.2713 - val_loss: 0.7510 - val_accuracy: 0.5110 - val_f1_score: 0.2712\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7519 - accuracy: 0.4955 - f1_score: 0.2711 - val_loss: 0.7503 - val_accuracy: 0.5110 - val_f1_score: 0.2710\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7514 - accuracy: 0.4925 - f1_score: 0.2709 - val_loss: 0.7496 - val_accuracy: 0.5110 - val_f1_score: 0.2708\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.7504 - accuracy: 0.4955 - f1_score: 0.2708 - val_loss: 0.7489 - val_accuracy: 0.5110 - val_f1_score: 0.2707\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7499 - accuracy: 0.4926 - f1_score: 0.2706 - val_loss: 0.7482 - val_accuracy: 0.5110 - val_f1_score: 0.2705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7490 - accuracy: 0.4951 - f1_score: 0.2704 - val_loss: 0.7475 - val_accuracy: 0.5110 - val_f1_score: 0.2703\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7482 - accuracy: 0.4971 - f1_score: 0.2703 - val_loss: 0.7468 - val_accuracy: 0.5110 - val_f1_score: 0.2702\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.7480 - accuracy: 0.4891 - f1_score: 0.2701 - val_loss: 0.7462 - val_accuracy: 0.5110 - val_f1_score: 0.2700\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7469 - accuracy: 0.4954 - f1_score: 0.2699 - val_loss: 0.7455 - val_accuracy: 0.5110 - val_f1_score: 0.2698\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.7463 - accuracy: 0.4949 - f1_score: 0.2698 - val_loss: 0.7449 - val_accuracy: 0.5110 - val_f1_score: 0.2697\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7450 - accuracy: 0.5069 - f1_score: 0.2696 - val_loss: 0.7443 - val_accuracy: 0.5110 - val_f1_score: 0.2695\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.7449 - accuracy: 0.4972 - f1_score: 0.2695 - val_loss: 0.7437 - val_accuracy: 0.5110 - val_f1_score: 0.2694\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7444 - accuracy: 0.4952 - f1_score: 0.2693 - val_loss: 0.7431 - val_accuracy: 0.5110 - val_f1_score: 0.2692\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7437 - accuracy: 0.4969 - f1_score: 0.2691 - val_loss: 0.7425 - val_accuracy: 0.5110 - val_f1_score: 0.2690\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7429 - accuracy: 0.5002 - f1_score: 0.2690 - val_loss: 0.7419 - val_accuracy: 0.5110 - val_f1_score: 0.2689\n"
     ]
    }
   ],
   "source": [
    "X=np.random.random((10000, 2000))\n",
    "y=np.random.random((10000))\n",
    "Y=np.concatenate((np.array(1*(y<0.5)).reshape(1, len(y)), np.array(1*(y==0.5)).reshape(1, len(y)), np.array(1*(y>0.5)).reshape(1, len(y))), axis=0)\n",
    "Y=np.transpose(Y)\n",
    "\n",
    "callback = EarlyStopping(monitor='val_f1_score', patience=3)\n",
    "\n",
    "trainX= X[:int(len(Y)*0.9), :]  #a[:1000, :]\n",
    "trainY= Y[:int(len(Y)*0.9), :]         #Y[:1000]\n",
    "testX= X[int(len(Y)*0.9):, :]   #a[1000:2000, :]\n",
    "testY= Y[int(len(Y)*0.9):, :]  #Y[1000:2000]\n",
    "np.save('testY', testY)\n",
    "np.save('testX', testX)\n",
    "\n",
    "look_back=1\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(1, X.shape[1])))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1])\n",
    "history=model.fit(trainX, trainY, epochs=100, shuffle=True, batch_size=1024,  validation_split=0.1111, callbacks=[callback], verbose=1)\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=np.load('X.npy')\n",
    "idx_fail=np.load('idx_fail.npy')\n",
    "X=np.delete(X, idx_fail, axis=0)\n",
    "ki=np.load('ki_train.npy')\n",
    "Y=1*(ki=='D')\n",
    "Y=np.delete(Y, idx_fail)\n",
    "\n",
    "names_span=['50000', '100000', '150000', '200000', '_f']\n",
    "\n",
    "for name in names_span:\n",
    "\tif name=='50000':\n",
    "\t\tXX=np.load('X_ki'+name+'.npy')\n",
    "\t\tidx_fail=np.load('idx_fail_ki'+name+'.npy')\n",
    "\t\tXX=np.delete(XX, idx_fail, axis=0)\n",
    "\telse:\n",
    "\t\tXX_aux=np.load('X_ki'+name+'.npy')\n",
    "\t\tidx_fail=np.load('idx_fail_ki'+name+'.npy')\n",
    "\t\tXX_aux=np.delete(XX_aux, idx_fail, axis=0)\n",
    "\t\tXX=np.concatenate((XX, XX_aux))\n",
    "\n",
    "AA=2*np.ones(XX.shape[0])\n",
    "Y=np.concatenate((Y, AA))\n",
    "perm=np.random.RandomState(seed=42).permutation(len(Y))\n",
    "Y=Y[perm]\n",
    "print(len(Y))\n",
    "print(X.shape)\n",
    "print(XX.shape)\n",
    "X=np.concatenate((X, XX))\n",
    "X=X[perm, :]\n",
    "Y=Y.reshape(len(Y), 1)\n",
    "Y=np.concatenate((1*(Y==0), 1*(Y==1), 1*(Y==2)), axis=1)\n",
    "\n",
    "np.save('glove/X', X)\n",
    "np.save('glove/Y', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "el=np.load('el.npy', allow_pickle=True)\n",
    "ki=np.load('ki.npy', allow_pickle=True)\n",
    "numalt=np.load('numalt.npy', allow_pickle=True)\n",
    "nume=np.load('nume.npy', allow_pickle=True)\n",
    "assert len(el)==len(ki)\n",
    "assert len(nume)==len(numalt)\n",
    "assert len(el)==len(nume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404 Client Error: Not Found for url: https://huggingface.co/bert//resolve/main/config.json\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load config for 'bert/'. Make sure that:\n\n- 'bert/' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'bert/' is the correct path to a directory containing a config.json file\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                 \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/bert//resolve/main/config.json",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5eb842df8891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0m_from_auto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_auto_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_pipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             )\n\u001b[1;32m   1202\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \"\"\"\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             logger.warn(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             )\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load config for 'bert/'. Make sure that:\n\n- 'bert/' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'bert/' is the correct path to a directory containing a config.json file\n\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import time\n",
    "import transformers\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "el=np.load('el.npy', allow_pickle=True)\n",
    "nume=np.load('nume.npy', allow_pickle=True)\n",
    "ki=np.load('ki.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=[['killed', 'died', 'dead',  'death', 'decease', 'assassinated', 'dies', 'kill', 'deceased', 'victims'\n",
    "], ['injury', 'injured', 'wound', 'wounded', 'hurt', 'damaged']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 215.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "idx_together=[]\n",
    "idx_numerals=[]\n",
    "tokenized_text_vec=[]\n",
    "indexed_tokens_vec=[]\n",
    "mask_vec=[]\n",
    "fail=0\n",
    "segments_ids_vec = [] #[1] * len(tokenized_text[0])\n",
    "max_len=0\n",
    "for idx, txt in tqdm(enumerate(lis)):\n",
    "    try:\n",
    "        idx_numerals.append([txt.index('numnumnum'), len(txt)-txt.index('numnumnum')-1])\n",
    "        new_idx_together=[]\n",
    "        txt=str(txt)[1:-1].replace('\\'', '')\n",
    "        txt=txt.replace(',', '')\n",
    "        txt=txt.replace('numnumnum', nume[idx])\n",
    "        # Add the special tokens.\n",
    "        marked_text = \"[CLS] \" + txt + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        max_len=max(len(tokenized_text), max_len)\n",
    "        mask=np.concatenate((np.ones(len(tokenized_text)), np.zeros(int(100-len(tokenized_text)))))\n",
    "        while len(tokenized_text)<100: tokenized_text.append(\"[PAD]\")\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids=[1]*len(tokenized_text)\n",
    "        for idx, segment in enumerate(tokenized_text):\n",
    "            if segment[:2]=='##': new_idx_together.append(idx)\n",
    "        idx_together.append(new_idx_together)\n",
    "        tokenized_text_vec.append(tokenized_text)\n",
    "        indexed_tokens_vec.append(indexed_tokens)\n",
    "        segments_ids_vec.append(segments_ids)     \n",
    "        mask_vec.append(mask.tolist())\n",
    "    except:\n",
    "        fail+=1\n",
    "tokens_tensor = torch.tensor([indexed_tokens_vec])\n",
    "segments_tensors = torch.tensor([segments_ids_vec])\n",
    "attention_mask = torch.tensor([mask_vec])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 254.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['killed', 'died', 'dead', 'death', 'decease', 'assassinated', 'dies', 'kill', 'deceased', 'victims']\n",
      "['injury', 'injured', 'wound', 'wounded', 'hurt', 'damaged']\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "idx_together=[]\n",
    "idx_numerals=[]\n",
    "tokenized_text_vec=[]\n",
    "indexed_tokens_vec=[]\n",
    "mask_vec=[]\n",
    "fail=0\n",
    "segments_ids_vec = [] #[1] * len(tokenized_text[0])\n",
    "max_len=0\n",
    "for idx, txt in tqdm(enumerate(lis)):\n",
    "    print(txt)\n",
    "    try:\n",
    "        new_idx_together=[]\n",
    "        txt=str(txt)[1:-1].replace('\\'', '')\n",
    "        txt=txt.replace(',', '')\n",
    "        # Add the special tokens.\n",
    "        marked_text = \"[CLS] \" + txt + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        max_len=max(len(tokenized_text), max_len)\n",
    "        mask=np.concatenate((np.ones(len(tokenized_text)), np.zeros(int(100-len(tokenized_text)))))\n",
    "        while len(tokenized_text)<100: tokenized_text.append(\"[PAD]\")\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids=[1]*len(tokenized_text)\n",
    "        for idx, segment in enumerate(tokenized_text):\n",
    "            if segment[:2]=='##': new_idx_together.append(idx)\n",
    "        idx_together.append(new_idx_together)\n",
    "        tokenized_text_vec.append(tokenized_text)\n",
    "        indexed_tokens_vec.append(indexed_tokens)\n",
    "        segments_ids_vec.append(segments_ids)     \n",
    "        mask_vec.append(mask.tolist())\n",
    "    except:\n",
    "        fail+=1\n",
    "tokens_tensor = torch.tensor([indexed_tokens_vec])\n",
    "segments_tensors = torch.tensor([segments_ids_vec])\n",
    "attention_mask = torch.tensor([mask_vec])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 100])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor[0], attention_mask[0], segments_tensors[0])\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 13, 768])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings = token_embeddings.permute(1, 2, 0, 3)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_base=0\n",
    "embeds=[]\n",
    "for idx_4, sentence in enumerate(token_embeddings):\n",
    "    token_vecs_sum = []\n",
    "    mask=attention_mask[0][idx_4]\n",
    "    idx_tog=idx_together[idx_4]\n",
    "    primer=True \n",
    "    for idx_2, token in enumerate(sentence):\n",
    "        new_idx=99-idx_2\n",
    "        token=sentence[new_idx]\n",
    "        if not primer and new_idx>0:\n",
    "            new_cont+=1\n",
    "            sum_vec += torch.sum(token[-4:], dim=0)\n",
    "            if not new_idx in idx_tog:\n",
    "                sum_vec=sum_vec/new_cont\n",
    "                token_vecs_sum.append(sum_vec)\n",
    "                sum_vec=torch.zeros(768)\n",
    "                new_cont=0\n",
    "            else:\n",
    "                assert tokenized_text_vec[idx_4][new_idx][:2]=='##'\n",
    "        if primer and mask[new_idx]==1:\n",
    "            primer=False\n",
    "            sum_vec=torch.zeros(768)\n",
    "            new_cont=0\n",
    "    token_vecs_sum=torch.stack(token_vecs_sum)\n",
    "    embeds.append(token_vecs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (768,1) doesn't match the broadcast shape (768,768)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-410-f5cc7baf494f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0maux\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcontador\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0maux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcontador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (768,1) doesn't match the broadcast shape (768,768)"
     ]
    }
   ],
   "source": [
    "vec=np.array((768, 1))\n",
    "for el in embeds:\n",
    "    print(el.shape)\n",
    "    contador=0\n",
    "    aux=np.zeros((768, 1))\n",
    "    for word in el:\n",
    "        aux+=np.array(word)\n",
    "        contador+=1\n",
    "    aux=aux/contador\n",
    "    vec=np.concatenate((vec, aux))\n",
    "\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=np.zeros((768, 2))\n",
    "vec[:, 0]=embeds[0].mean(axis=0)\n",
    "vec[:, 1]=embeds[1].mean(axis=0)\n",
    "vec=np.transpose(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('vec_bert', vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=embeds[1][0, 0]+embeds[1][1, 0]+embeds[1][2, 0]+embeds[1][3, 0]+embeds[1][4, 0]+embeds[1][5, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.zeros((1, 768*12))\n",
    "for idx, embed in enumerate(embeds):\n",
    "    aux=np.zeros((1, 768*12))\n",
    "    for idx_2, word in enumerate(embed):\n",
    "        n=5-idx_2+idx_numerals[idx][1]\n",
    "        aux[0, n*768:(n+1)*768]=word\n",
    "    X=np.concatenate([X, aux], axis=0)\n",
    "X=X[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "idx_base=0\n",
    "embeds=[]\n",
    "for idx, sentence in enumerate(token_embeddings):\n",
    "    token_vecs_sum = []\n",
    "    mask=attention_mask[0][idx_base+idx]\n",
    "    idx_tog=idx_together[idx_base+idx]\n",
    "    primer=True \n",
    "    for idx_2, token in enumerate(sentence):\n",
    "        # `token` is a [12 xe 768] tensor\n",
    "        new_idx=99-idx_2\n",
    "        token=sentence[new_idx]\n",
    "        if not primer and new_idx>0:\n",
    "            new_cont+=1\n",
    "            sum_vec += torch.sum(token[-4:], dim=0)\n",
    "            if not new_idx in idx_tog:\n",
    "                sum_vec=sum_vec/new_cont\n",
    "                token_vecs_sum.append(sum_vec)\n",
    "                sum_vec=torch.zeros(768)\n",
    "                new_cont=0\n",
    "        if primer and mask[new_idx]==1:\n",
    "            primer=False\n",
    "            sum_vec=torch.zeros(768)\n",
    "            new_cont=0\n",
    "    if idx_numerals[idx][0]==0:\n",
    "        aux=token_vecs_sum[idx_numerals[idx][1]:]\n",
    "        B = torch.stack(aux).mean(axis=0).reshape(len(token_vecs_sum)-idx_numerals[idx][1]-idx_numerals[idx][0], 768)\n",
    "        if idx_numerals[idx][1]==0:\n",
    "            token_vecs_sum=torch.cat([B], axis=-2)\n",
    "        else:\n",
    "            A = torch.stack(token_vecs_sum[:idx_numerals[idx][1]], dim=0).reshape(idx_numerals[idx][1], 768)\n",
    "            token_vecs_sum=torch.cat([A, B], axis=-2)\n",
    "    else: \n",
    "        aux=token_vecs_sum[idx_numerals[idx][1]:-idx_numerals[idx][0]]\n",
    "        C = torch.stack(token_vecs_sum[-idx_numerals[idx][0]:], dim=0).reshape(idx_numerals[idx][0], 768)\n",
    "        B = torch.stack(aux).mean(axis=0).reshape(len(token_vecs_sum)-idx_numerals[idx][1]-idx_numerals[idx][0], 768)\n",
    "        if idx_numerals[idx][1]==0:\n",
    "            token_vecs_sum=torch.cat([B, C], axis=-2)\n",
    "        else:\n",
    "            A = torch.stack(token_vecs_sum[:idx_numerals[idx][1]], dim=0).reshape(idx_numerals[idx][1], 768)\n",
    "            token_vecs_sum=torch.cat([A, B, C], axis=-2)\n",
    "    embeds.append(token_vecs_sum)\n",
    "    print(len(token_vecs_sum)-idx_numerals[idx][1]-idx_numerals[idx][0])\n",
    "    \n",
    "X=np.zeros((1, 768*12))\n",
    "for idx, embed in enumerate(embeds):\n",
    "    aux=np.zeros((1, 768*12))\n",
    "    for idx_2, word in enumerate(embed):\n",
    "        n=5-idx_2+idx_numerals[idx][1]\n",
    "        aux[0, n*768:(n+1)*768]=word\n",
    "    X=np.concatenate([X, aux], axis=0)\n",
    "X=X[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.zeros((1, 768*12))\n",
    "for idx, embed in enumerate(embeds):\n",
    "    aux=np.zeros((1, 768*12))\n",
    "    for idx_2, word in enumerate(embed):\n",
    "        n=5-idx_2+idx_numerals[idx][1]\n",
    "        aux[0, n*768:(n+1)*768]=word\n",
    "    X=np.concatenate([X, aux], axis=0)\n",
    "X=X[1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.compat.v1.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "#from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa \n",
    "from keras import metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(history, metric, name):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics)\n",
    "    plt.plot(epochs, val_metrics)\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.savefig(name+metric)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2177366018295288,\n",
       " 0.2207740992307663,\n",
       " 0.2210048884153366,\n",
       " 0.2211650162935257,\n",
       " 0.2209213525056839,\n",
       " 0.2210668921470642,\n",
       " 0.22107140719890594,\n",
       " 0.22102689743041992,\n",
       " 0.2209825962781906,\n",
       " 0.22102223336696625]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(history, 'loss', 'figures/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.random.random((10000, 2000))\n",
    "y=np.random.random((10000))\n",
    "Y=np.concatenate((np.array(1*(y<0.5)).reshape(1, len(y)), np.array(1*(y==0.5)).reshape(1, len(y)), np.array(1*(y>0.5)).reshape(1, len(y))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 34s 203ms/step - loss: 1.0252 - accuracy: 0.4541 - f1_score: 0.2088 - val_loss: 0.9579 - val_accuracy: 0.5000 - val_f1_score: 0.2210\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.9558 - accuracy: 0.5024 - f1_score: 0.2214 - val_loss: 0.9517 - val_accuracy: 0.5000 - val_f1_score: 0.2223\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 0.9497 - accuracy: 0.5020 - f1_score: 0.2224 - val_loss: 0.9457 - val_accuracy: 0.5000 - val_f1_score: 0.2228\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.9428 - accuracy: 0.5053 - f1_score: 0.2229 - val_loss: 0.9398 - val_accuracy: 0.5000 - val_f1_score: 0.2230\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.9366 - accuracy: 0.5069 - f1_score: 0.2231 - val_loss: 0.9341 - val_accuracy: 0.5000 - val_f1_score: 0.2231\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.9306 - accuracy: 0.5080 - f1_score: 0.2232 - val_loss: 0.9285 - val_accuracy: 0.5000 - val_f1_score: 0.2232\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 0.9257 - accuracy: 0.5059 - f1_score: 0.2232 - val_loss: 0.9231 - val_accuracy: 0.5000 - val_f1_score: 0.2233\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.9210 - accuracy: 0.5035 - f1_score: 0.2233 - val_loss: 0.9179 - val_accuracy: 0.5000 - val_f1_score: 0.2233\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.9154 - accuracy: 0.5051 - f1_score: 0.2233 - val_loss: 0.9129 - val_accuracy: 0.5000 - val_f1_score: 0.2233\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.9092 - accuracy: 0.5096 - f1_score: 0.2234 - val_loss: 0.9080 - val_accuracy: 0.5000 - val_f1_score: 0.2234\n",
      "Train Score: 0.43 RMSE\n",
      "Test Score: 0.43 RMSE\n",
      "F1: Train Score: 0.00 I - 0.00 K - 0.67 Other\n",
      "F1: Test Score: 0.00 I - 0.00 K - 0.67 Other\n",
      "Train Score: 0.50 Categorical Accuracy\n",
      "Test Score: 0.51 Categorical Accuracy\n"
     ]
    }
   ],
   "source": [
    "Y=np.transpose(Y)\n",
    "f1 = tfa.metrics.F1Score(3)\n",
    "trainX= X[:int(len(Y)*0.9), :]  #a[:1000, :]\n",
    "trainY= Y[:int(len(Y)*0.9), :]         #Y[:1000]\n",
    "testX= X[int(len(Y)*0.9):, :]   #a[1000:2000, :]\n",
    "testY= Y[int(len(Y)*0.9):, :]  #Y[1000:2000]\n",
    "np.save('testY', testY)\n",
    "np.save('testX', testX)\n",
    "\n",
    "look_back=1\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(1, X.shape[1])))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1])\n",
    "history=model.fit(trainX, trainY, epochs=10, shuffle=True, batch_size=1024,  validation_split=0.1111, verbose=1)\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "#trainPredict = scaler.inverse_transform(trainPredict)\n",
    "#trainY = scaler.inverse_transform([trainY])\n",
    "#testPredict = scaler.inverse_transform(testPredict)\n",
    "#testY = scaler.inverse_transform([testY])\n",
    "\n",
    "\n",
    "plot_metric(history, 'accuracy', 'figures/')\n",
    "plot_metric(history, 'loss', 'figures/')\n",
    "plot_metric(history, 'f1_score', 'figures/')\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "trainScore = f1(trainY, trainPredict).numpy()\n",
    "print('F1: Train Score: %.2f I - %.2f K - %.2f Other' % (trainScore[0], trainScore[1], trainScore[2]))\n",
    "testScore = f1(testY, testPredict).numpy()\n",
    "print('F1: Test Score: %.2f I - %.2f K - %.2f Other' % (testScore[0], testScore[1], testScore[2]))\n",
    "\n",
    "trainScore=metrics.categorical_accuracy(trainY, trainPredict)\n",
    "print('Train Score: %.2f Categorical Accuracy' % (trainScore.numpy().mean()))\n",
    "testScore=metrics.categorical_accuracy(testY, testPredict)\n",
    "print('Test Score: %.2f Categorical Accuracy' % (testScore.numpy().mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('X.npy')\n",
    "idx_fail=np.load('idx_fail.npy')\n",
    "X=np.delete(X, idx_fail, axis=0)\n",
    "ki=np.load('ki_train.npy')\n",
    "Y=1*(ki=='D')\n",
    "Y=np.delete(Y, idx_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000e+02, 2.000e+02, 3.000e+02, ..., 2.280e+05, 2.281e+05,\n",
       "       2.282e+05])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_max=int(228200/100)+1\n",
    "maxims_no=np.linspace(0, 0+(100*no_max),no_max,endpoint=False)[1:]\n",
    "maxims_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "y=np.zeros((1,1))\n",
    "X=np.zeros((1, 9216))\n",
    "grups=[50000,100000, 150000, 200000, 250000, 300000] \n",
    "for idx, grup in tqdm(enumerate(grups)):\n",
    "    X_ki_aux=np.load('bert/aux/X_ki_'+str(maxim)+'.npy')\n",
    "    ki_aux=np.load('bert/aux/y_ki_'+str(maxim)+'.npy')\n",
    "    X=np.concatenate((X, X_ki_aux))\n",
    "    y=np.concatenate((y, ki_aux), axis=1)\n",
    "    assert y.shape[1]==X.shape[0]\n",
    "    assert X.shape[1]==768*12\n",
    "    \n",
    "X=X[1:, :]\n",
    "y=y[:, 1:]            \n",
    "            \n",
    "\n",
    "grups=[50000,100000, 150000, 200000, 250000] \n",
    "\n",
    "\n",
    "for idx, grup in tqdm(enumerate(grups)):\n",
    "    X_ki_aux=np.load('bert/aux2/X_no_'+str(maxim)+'.npy')\n",
    "    ki_aux=2*np.ones((1, X_ki_aux.shape[0]))\n",
    "    X=np.concatenate((X, X_ki_aux))\n",
    "    y=np.concatenate((y, ki_aux.reshape(1, len(ki_aux))), axis=1)\n",
    "    assert y.shape[1]==X.shape[0]\n",
    "    assert X.shape[1]==768*12\n",
    "\n",
    "perm=np.random.RandomState(seed=42).permutation(y.shape[1])\n",
    "Y=y[:, perm]\n",
    "X=X[perm, :]\n",
    "Y=Y.reshape(Y.shape[1], 1)\n",
    "Y=np.concatenate((1*(Y==0), 1*(Y==1), 1*(Y==2)), axis=1)\n",
    "np.save('bert/X.npy', X)\n",
    "np.save('bert/Y.npy', Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "no_max=int(228200/100)+1\n",
    "maxims_no=np.linspace(0, 0+(100*no_max),no_max,endpoint=False)[1:]\n",
    "ki_max=int(251000/100)+1\n",
    "maxims_ki=np.linspace(0, 0+(100*ki_max),ki_max,endpoint=False)[1:]\n",
    "\n",
    "\n",
    "y=np.zeros((1,1))\n",
    "X=np.zeros((1, 9216))\n",
    "for idx, maxim in tqdm(enumerate(maxims_ki)):\n",
    "    maxim=int(maxim)\n",
    "    X_ki_aux=np.load('bert/ki/X_ki_'+str(maxim)+'.npy')\n",
    "    ki_aux=np.load('bert/ki/ki_'+str(maxim)+'.npy')\n",
    "    ki_aux=1*(ki_aux=='D')\n",
    "    X=np.concatenate((X, X_ki_aux))\n",
    "    y=np.concatenate((y, ki_aux.reshape(1, len(ki_aux))), axis=1)\n",
    "    assert y.shape[1]==X.shape[0]\n",
    "    assert X.shape[1]==768*12\n",
    "X=X[1:, :]\n",
    "y=y[:, 1:]\n",
    "\n",
    "np.save('bert/X_mid.npy', X)\n",
    "np.save('bert/y_mid.npy', y)\n",
    "\n",
    "for idx, maxim in tqdm(enumerate(maxims_no)):\n",
    "    maxim=int(maxim)\n",
    "    X_no_aux=np.load('bert/no/X_no_'+str(maxim)+'.npy')\n",
    "    no_aux=2*np.ones((1, X_no_aux.shape[0]))\n",
    "    X=np.concatenate((X, X_no_aux))\n",
    "    y=np.concatenate((y, no_aux), axis=1)\n",
    "    assert y.shape[1]==X.shape[0]\n",
    "    assert X.shape[1]==768*12\n",
    "\n",
    "\n",
    "perm=np.random.RandomState(seed=42).permutation(y.shape[1])\n",
    "Y=y[:, perm]\n",
    "X=X[perm, :]\n",
    "Y=Y.reshape(Y.shape[1], 1)\n",
    "Y=np.concatenate((1*(Y==0), 1*(Y==1), 1*(Y==2)), axis=1)\n",
    "np.save('bert/X.npy', X)\n",
    "np.save('bert/Y.npy', Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_span=['50000', '100000', '150000', '200000', '_f']\n",
    "\n",
    "\n",
    "for name in names_span:\n",
    "\tif name=='50000':\n",
    "\t\tXX=np.load('X_ki'+name+'.npy')\n",
    "\t\tidx_fail=np.load('idx_fail_ki'+name+'.npy')\n",
    "\t\tXX=np.delete(XX, idx_fail, axis=0)\n",
    "\telse:\n",
    "\t\tXX_aux=np.load('X_ki'+name+'.npy')\n",
    "\t\tidx_fail=np.load('idx_fail_ki'+name+'.npy')\n",
    "\t\tXX_aux=np.delete(XX_aux, idx_fail, axis=0)\n",
    "\t\tXX=np.concatenate((XX, XX_aux))\n",
    "\n",
    "AA=2*np.ones(XX.shape[0])\n",
    "Y=np.concatenate((Y, AA))\n",
    "perm=np.random.RandomState(seed=42).permutation(len(Y))\n",
    "Y=Y[perm]\n",
    "print(len(Y))\n",
    "print(X.shape)\n",
    "print(XX.shape)\n",
    "X=np.concatenate((X, XX))\n",
    "X=X[perm, :]\n",
    "Y=Y.reshape(len(Y), 1)\n",
    "Y=np.concatenate((1*(Y==0), 1*(Y==1), 1*(Y==2)), axis=1)\n",
    "\n",
    "print('Model')\n",
    "print(params.model)\n",
    "\n",
    "print('Directory')\n",
    "print(params.dir)\n",
    "\n",
    "\n",
    "print('Lets see the shapes')\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import scipy.linalg\n",
    "from scipy.linalg import lstsq\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "tt=time.time()\n",
    "Y=np.load('bert/Y.npy')\n",
    "print(time.time()-tt)\n",
    "\n",
    "\n",
    "tt=time.time()\n",
    "X=np.load('bert/X_train.npy', mmap_mode='r')\n",
    "print(time.time()-tt)\n",
    "\n",
    "\n",
    "vec=np.load(\"bert/vec_vert.npy\")\n",
    "kill=vec[0, :].reshape((1, 768))\n",
    "injured=vec[1, :].reshape((1, 768))\n",
    "\n",
    "class_weight = {0: 9.1, 1: 2.78, 2: 1.92}\n",
    "\n",
    "Y_train=np.zeros((Y.shape[0], 300))\n",
    "\n",
    "for i in range(Y.shape[0]):\n",
    "    if Y[i, 0]==1: aux_emb=injured #np.ones((1, 300))  #np.concatenate((np.ones((1, 100)), np.zeros((1, 100)), np.zeros((1, 100))), axis=1)    #5*(injured-kill) #np.concatenate((np.ones((1, 100)), np.zeros((1, 100)), np.zeros((1, 100))), axis=1) #kill-injured   #np.concatenate((np.ones((1, 100)), np.zeros((1, 100)), np.zeros((1, 100))), axis=1)   #np.ones((1, 300))\n",
    "    if Y[i, 1]==1: aux_emb=kill #-np.ones((1, 300))  #np.concatenate((np.zeros((1, 100)), np.ones((1, 100)), np.zeros((1, 100))), axis=1)     #5*(kill-injured)  ##injured-kill #np.concatenate((np.zeros((1, 100)), np.ones((1, 100)), np.zeros((1, 100))), axis=1)   #-np.ones((1, 300))\n",
    "    if Y[i, 2]==1: aux_emb=np.zeros((1, 768)) #np.zeros((1, 300))  #np.concatenate((np.zeros((1, 100)), np.zeros((1, 100)), np.ones((1, 100))), axis=1) #np.zeros((1, 300))  #np.concatenate((np.zeros((1, 100)), np.zeros((1, 100)), np.ones((1, 100))), axis=1) #np.zeros((1, 300))   #np.concatenate((np.zeros((1, 100)), np.zeros((1, 100)), np.ones((1, 100))), axis=1)\n",
    "    Y_train[i, :]=aux_emb #+X[i, 300*5:300*6])/2\n",
    "    #Y_train[i, :]=(np.sqrt(class_weight[Y[i]]))*Y_train[i, :] #/2\n",
    "np.save(\"Y_train\", Y_train)\n",
    "\n",
    "'''\n",
    "bad_idx=[]\n",
    "for idx in range(len(Y)):\n",
    "    contador=0\n",
    "    aux=np.zeros((1, 300))\n",
    "    for idx_2 in range(11):\n",
    "        if (X[idx, idx_2*300:(idx_2+1)*300]**2).sum()!=0.0: ++contador\n",
    "        aux=X[idx, idx_2*300:(idx_2+1)*300]+aux\n",
    "    if contador==0:\n",
    "        bad_idx.append(idx)\n",
    "    else: X[idx, 1500:1800]=(np.sqrt(class_weight[Y[idx]]))*aux #/contador\n",
    "\n",
    "X=X[:, 1500:1800]\n",
    "'''\n",
    "\n",
    "print(\"We are doing dead, injury,... AVERAGING!\")\n",
    "\n",
    "for size in [1000, 10000, 50000, 100000]:\n",
    "    print(\"New size is \"+ str(size))\n",
    "    p, res, rnk, s = lstsq(X[:size], Y_train[:size])\n",
    "    np.save(\"A/A_co\"+str(size), p)\n",
    "    print(\"Silhouette_score\")\n",
    "    print(\"Train\")\n",
    "    #print(sklearn.metrics.silhouette_score(X[:size, 1500:1800], Y[:size]))\n",
    "    print(sklearn.metrics.silhouette_score(X[:size, :], Y[:size]))\n",
    "    print(\"Val\")\n",
    "    #print(sklearn.metrics.silhouette_score(X[100000:, 1500:1800], Y[100000:]))\n",
    "    print(sklearn.metrics.silhouette_score(X[100000:, :], Y[100000:]))\n",
    "    print(\"New Silhouette_score\")\n",
    "    print(\"Train\")\n",
    "    print(sklearn.metrics.silhouette_score(np.matmul(X[:size], p), Y[:size]))\n",
    "    print(\"Val\")\n",
    "    print(sklearn.metrics.silhouette_score(np.matmul(X[100000:], p), Y[100000:]))\n",
    "    print(np.matmul(X[100000:], p).shape)\n",
    "    print(\"__________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.zeros(Y.shape[0])\n",
    "for i in range(Y.shape[0]):\n",
    "    if Y[i, 0]==1: y[idx]=0\n",
    "    if Y[i, 1]==1: y[idx]=1 \n",
    "    if Y[i, 2]==1: y[idx]=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I mean: 0.6900000000000001\n",
      "K mean: 0.7999999999999999\n",
      "O mean: 0.7999999999999999\n",
      "Train\n",
      "Mean F1 score:0.7633333333333333\n",
      "Val\n",
      "I mean: 0.6888888888888889\n",
      "K mean: 0.7999999999999999\n",
      "O mean: 0.7999999999999999\n",
      "SD: 0.011111111111111108\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "def avg(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "\n",
    "file_object  = open(\"aux.txt\", \"r\")\n",
    "a=file_object.readlines()\n",
    "IT=[]\n",
    "KT=[]\n",
    "OT=[]\n",
    "\n",
    "IV=[]\n",
    "KV=[]\n",
    "OV=[]\n",
    "\n",
    "for line in a:\n",
    "    if line[:8]=='F1: Test':\n",
    "        IT.append(float(line[line.find(' I')-4:line.find(' I')-1]))\n",
    "        KT.append(float(line[line.find(' K')-4:line.find(' K')-1]))\n",
    "        OT.append(float(line[line.find(' Other')-4:line.find(' Other')-1]))\n",
    "    else:\n",
    "        IV.append(float(line[line.find(' I')-4:line.find(' I')-1]))\n",
    "        KV.append(float(line[line.find(' K')-4:line.find(' K')-1]))\n",
    "        OV.append(float(line[line.find(' Other')-4:line.find(' Other')-1]))\n",
    "\n",
    "print(\"I mean: \"+str(avg(IT)))\n",
    "print(\"K mean: \"+str(avg(KT)))   \n",
    "print(\"O mean: \"+str(avg(OT)))    \n",
    "    \n",
    "print('Train')\n",
    "print('Mean F1 score:'+str((avg(IT)+avg(KT)+avg(OT))/3))\n",
    "    \n",
    "print('Val')\n",
    "print(\"I mean: \"+str(avg(IV)))\n",
    "print(\"K mean: \"+str(avg(KV)))   \n",
    "print(\"O mean: \"+str(avg(OV)))  \n",
    "print(\"SD: \"+str(((statistics.stdev(IV)+statistics.stdev(KV)+(statistics.stdev(OV)))/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F1: Test'"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean: 0.845\n",
      "Train Accuracy SD: 0.010801234497346443\n",
      "Val mean: 0.8000000000000003\n",
      "Val Accuracy SD: 0.010801234497346443\n"
     ]
    }
   ],
   "source": [
    "def avg(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "file_object  = open(\"aux2.txt\", \"r\")\n",
    "a=file_object.readlines()\n",
    "T=[]\n",
    "V=[]\n",
    "for line in a:\n",
    "    if line[:5]=='Test ':\n",
    "        T.append(float(line[line.find('.')-1:line.find('.')+3]))\n",
    "    else:\n",
    "        V.append(float(line[line.find('.')-1:line.find('.')+3]))\n",
    "        \n",
    "print(\"Train mean: \"+str(avg(T)))       \n",
    "print(\"Train Accuracy SD: \"+str(statistics.stdev(T))) \n",
    "\n",
    "print(\"Val mean: \"+str(avg(K)))  \n",
    "print(\"Val Accuracy SD: \"+str(statistics.stdev(V)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test Score: 0.85 Categorical Accuracy\\n'"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numalt=np.load('numalt.npy', allow_pickle=True)\n",
    "nume=np.load('nume.npy', allow_pickle=True)\n",
    "num_no=np.load('num_no_cont.npy', allow_pickle=True)\n",
    "ki=np.load('ki.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "#Dictionaries for reference\n",
    "ones = {\"1\":\"One\",\"2\":\"Two\",\"3\":\"Three\",\"4\":\"Four\",\"5\":\"Five\",\"6\":\"Six\", \"7\":\"Seven\",\"8\":\"Eight\",\"9\":\"Nine\"}\n",
    "ones_B = {\"01\":\"One\",\"02\":\"Two\",\"03\":\"Three\",\"04\":\"Four\",\"05\":\"Five\",\"06\":\"Six\", \"07\":\"Seven\",\"08\":\"Eight\",\"09\":\"Nine\"}\n",
    "afterones = {\"10\":\"Ten\",\"11\":\"Eleven\",\"12\":\"Twelve\",\"13\":\"Thirteen\",\"14\":\"Fourteen\",\"15\":\"Fifteen\",\"16\":\"Sixteen\", \"17\":\"Seventeen\",\"18\":\"Eighteen\",\"19\":\"Nineteen\"}\n",
    "tens = {\"2\":\"Twenty\",\"3\":\"Thirty\",\"4\":\"Fourty\",\"5\":\"Fifty\",\"6\":\"Sixty\", \"7\":\"Seventy\",\"8\":\"Eighty\",\"9\":\"Ninety\"}\n",
    "grand={0:\" Billion, \",1:\" Million, \",2:\" Thousand, \",3:\"\"}\n",
    "\n",
    "#Function converting number to words of 3 digit\n",
    "def num_to_wrds(val, lead=False, sign=' '):\n",
    "    val=str(val)\n",
    "    ans = \"\"\n",
    "    if lead:\n",
    "        if len(val)>6 and val[-6:]=='000000':\n",
    "            aux=val[:-6]\n",
    "            return str(aux)+ ' million'\n",
    "        elif len(val)>3 and val[-3:]=='000':\n",
    "            aux=val[:-3]\n",
    "            return str(aux)+ ' thousand'\n",
    "    if len(val)>6:\n",
    "        if val[:-6]!='000':\n",
    "            aux=val[:-6]\n",
    "            while len(aux)<3: aux='0'+aux\n",
    "            ans=num_to_wrds(aux, sign=sign)+ ' million '\n",
    "        val=val[-6:]\n",
    "    if len(val)>3:\n",
    "        if val[:-3]!='000':\n",
    "            aux=val[:-3]\n",
    "            while len(aux)<3: aux='0'+aux\n",
    "            ans=ans+num_to_wrds(aux, sign=sign)+ ' thousand '\n",
    "        val=val[3:]\n",
    "    while len(val)<3: val='0'+val\n",
    "    if val[0] in ones:\n",
    "        x = val\n",
    "        ans = ans + ones[val[0]] + \" hundred \"\n",
    "        #if val[1:]!='00':\n",
    "            #ans = ans + \" and \"\n",
    "    if val[1:] in afterones:\n",
    "        ans = ans + afterones[val[1:]] + \" \"\n",
    "    elif val[1] in tens:\n",
    "        ans = ans + tens[val[1]] \n",
    "        if val[2:3] in ones or val[1:3] in ones_B: ans=ans+sign\n",
    "        if val[2:3] in ones:\n",
    "            ans = ans + ones[val[2]]\n",
    "    if val[1:3] in ones_B:\n",
    "        ans = ans + ones[val[2]]\n",
    "    if ans=='': return ans\n",
    "    while ans[0]==' ': ans=ans[1:]\n",
    "    while ans[-1]==' ': ans=ans[:-1]\n",
    "    while ans!=ans.replace('  ', ' '):\n",
    "        ans=ans.replace('  ', ' ')\n",
    "    return str(ans.lower())\n",
    "\n",
    "nums={}\n",
    "for idx in range(1000):\n",
    "    nums[num_to_wrds(idx+1, sign='-')]=idx+1\n",
    "\n",
    "nums_no=[]   \n",
    "for ele in num_no:\n",
    "    if ele[-2:]=='.0': ele=ele[:-2]\n",
    "    ele=str(ele).replace('\\'', '')\n",
    "    ele=ele.replace(',', '')\n",
    "    ele=ele.replace('.', '')\n",
    "    if ele in nums:\n",
    "        nums_no.append(int(nums[ele]))\n",
    "    else:\n",
    "        nums_no.append(int(ele))\n",
    "        \n",
    "I=[] \n",
    "K=[]  \n",
    "for idx, ele in enumerate(numalt):\n",
    "    if ele[-2:]=='.0': ele=ele[:-2]\n",
    "    ele=str(ele).replace('\\'', '')\n",
    "    ele=ele.replace(',', '')\n",
    "    ele=ele.replace('.', '')\n",
    "    if ki[idx]=='I':\n",
    "        I.append(int(ele))\n",
    "    else:\n",
    "        K.append(int(ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251006"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(K)+len(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "plt.hist(x=nums_no, bins='auto', alpha=0.5, histtype='stepfilled', range=[1, 100], label='Other')\n",
    "plt.hist(x=K, bins='auto', alpha=0.5, histtype='stepfilled', range=[1, 100],  label='Deaths')\n",
    "plt.hist(x=I, bins='auto', alpha=0.5, histtype='stepfilled', range=[1, 100],  label='Injuries')\n",
    "plt.xlabel('Number')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of numbers for each category')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('hist_100')\n",
    "plt.show()\n",
    "                            #alpha=0.7, rwidth=0.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('My Very Own Histogram')\n",
    "plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
